name: API Workload Benchmark

on:
  push:
    branches: [main]
    paths:
      - 'benches/api/**'
      - 'src/**'
      - 'lambars-derive/**'
      - 'Cargo.toml'
      - 'Cargo.lock'
  pull_request:
    paths:
      - 'benches/api/**'
      - 'src/**'
      - 'lambars-derive/**'
      - 'Cargo.toml'
      - 'Cargo.lock'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  benchmark:
    name: API Workload Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      pull-requests: write

    steps:
      - name: Install wrk
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # ============================================
      # Baseline (main branch) - only for PRs
      # ============================================
      - name: Checkout main branch for baseline
        if: github.event_name == 'pull_request'
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Build and start services (main)
        if: github.event_name == 'pull_request'
        working-directory: benches/api/docker
        run: |
          docker compose -f compose.ci.yaml up -d --build --wait
          docker compose -f compose.ci.yaml ps

      - name: Setup test data (main)
        if: github.event_name == 'pull_request'
        working-directory: benches/api/benchmarks
        run: |
          chmod +x setup_test_data.sh
          API_URL=http://localhost:3002 ./setup_test_data.sh

      - name: Run baseline benchmarks (main)
        if: github.event_name == 'pull_request'
        working-directory: benches/api/benchmarks
        run: |
          chmod +x run_benchmark.sh
          API_URL=http://localhost:3002 DURATION=10s THREADS=2 CONNECTIONS=10 ./run_benchmark.sh --quick
          # Save baseline results
          BASELINE_DIR=$(ls -td results/*/ 2>/dev/null | head -1)
          if [ -n "$BASELINE_DIR" ]; then
            cp "$BASELINE_DIR/summary.txt" /tmp/baseline_summary.txt
            echo "Baseline results saved"
            cat /tmp/baseline_summary.txt
          fi

      - name: Stop services (main)
        if: github.event_name == 'pull_request'
        working-directory: benches/api/docker
        run: docker compose -f compose.ci.yaml down -v

      # ============================================
      # PR branch benchmarks
      # ============================================
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          clean: false

      - name: Build and start services
        working-directory: benches/api/docker
        run: |
          docker compose -f compose.ci.yaml up -d --build --wait
          docker compose -f compose.ci.yaml ps

      - name: Setup test data
        working-directory: benches/api/benchmarks
        run: |
          chmod +x setup_test_data.sh
          API_URL=http://localhost:3002 ./setup_test_data.sh

      - name: Run benchmarks
        id: benchmark
        working-directory: benches/api/benchmarks
        continue-on-error: true
        run: |
          chmod +x run_benchmark.sh
          API_URL=http://localhost:3002 DURATION=10s THREADS=2 CONNECTIONS=10 ./run_benchmark.sh --quick

      - name: Show API logs on failure
        if: failure()
        working-directory: benches/api/docker
        run: |
          echo "=== API Container Logs ==="
          docker compose -f compose.ci.yaml logs api --tail=100
          echo ""
          echo "=== Container Status ==="
          docker compose -f compose.ci.yaml ps -a

      - name: Check benchmark results
        working-directory: benches/api/benchmarks
        run: |
          # Find the most recent results directory
          RESULTS_DIR=$(ls -td results/*/ 2>/dev/null | head -1)
          if [ -z "$RESULTS_DIR" ]; then
            echo "No benchmark results found!"
            exit 1
          fi

          echo "Checking results in: $RESULTS_DIR"
          echo ""

          # Count successful benchmarks (those with actual requests)
          TOTAL=0
          PASSED=0
          FAILED_BENCHMARKS=""

          for result_file in "$RESULTS_DIR"/*.txt; do
            if [ -f "$result_file" ] && [ "$(basename "$result_file")" != "summary.txt" ]; then
              TOTAL=$((TOTAL + 1))
              BENCHMARK_NAME=$(basename "$result_file" .txt)

              # Check if requests were made (not 0 requests)
              REQUESTS=$(grep -o '[0-9]* requests in' "$result_file" | head -1 | awk '{print $1}')
              if [ -n "$REQUESTS" ] && [ "$REQUESTS" -gt 0 ]; then
                PASSED=$((PASSED + 1))
                echo "  $BENCHMARK_NAME: PASSED ($REQUESTS requests)"
              else
                FAILED_BENCHMARKS="$FAILED_BENCHMARKS $BENCHMARK_NAME"
                echo "  $BENCHMARK_NAME: FAILED (0 requests)"
              fi
            fi
          done

          echo ""
          echo "Summary: $PASSED/$TOTAL benchmarks passed"

          if [ "$PASSED" -lt "$TOTAL" ]; then
            echo ""
            echo "Failed benchmarks:$FAILED_BENCHMARKS"
            echo ""
            echo "This may indicate API issues. Check the API logs above."
            exit 1
          fi

      - name: Post benchmark results as PR comment
        if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Helper function to parse summary file
            function parseSummary(content) {
              const results = new Map();
              const bottleneck = { slowest: null, highestP99: null };
              const lines = content.split('\n');
              let currentBenchmark = null;
              let reqsPerSec = null;
              let avgLatency = null;
              let p50 = null, p75 = null, p90 = null, p99 = null;

              for (const line of lines) {
                const benchMatch = line.match(/^(\w+):$/);
                if (benchMatch) {
                  if (currentBenchmark && reqsPerSec !== null) {
                    results.set(currentBenchmark, { reqsPerSec, avgLatency, p50, p75, p90, p99 });
                  }
                  currentBenchmark = benchMatch[1];
                  reqsPerSec = null;
                  avgLatency = null;
                  p50 = null; p75 = null; p90 = null; p99 = null;
                }
                const reqsMatch = line.match(/Requests\/sec:\s*([\d.]+)/);
                if (reqsMatch) {
                  reqsPerSec = parseFloat(reqsMatch[1]);
                }
                const latencyMatch = line.match(/Avg Latency:\s*([\d.]+\w+)/);
                if (latencyMatch) {
                  avgLatency = latencyMatch[1];
                }
                // Parse latency percentiles
                const p50Match = line.match(/P50:\s*([\d.]+\w+)/);
                if (p50Match) p50 = p50Match[1];
                const p75Match = line.match(/P75:\s*([\d.]+\w+)/);
                if (p75Match) p75 = p75Match[1];
                const p90Match = line.match(/P90:\s*([\d.]+\w+)/);
                if (p90Match) p90 = p90Match[1];
                const p99Match = line.match(/P99:\s*([\d.]+\w+)/);
                if (p99Match) p99 = p99Match[1];

                // Parse bottleneck analysis
                const slowestMatch = line.match(/Slowest endpoint:\s*(\w+)\s*\(([\d.]+)\s*req\/s\)/);
                if (slowestMatch) {
                  bottleneck.slowest = { name: slowestMatch[1], rps: parseFloat(slowestMatch[2]) };
                }
                const highestP99Match = line.match(/Highest P99 latency:\s*(\w+)\s*\(([\d.]+\w+)\)/);
                if (highestP99Match) {
                  bottleneck.highestP99 = { name: highestP99Match[1], latency: highestP99Match[2] };
                }
              }
              if (currentBenchmark && reqsPerSec !== null) {
                results.set(currentBenchmark, { reqsPerSec, avgLatency, p50, p75, p90, p99 });
              }
              return { results, bottleneck };
            }

            // Find the most recent results directory
            const resultsBase = 'benches/api/benchmarks/results';
            const dirs = fs.readdirSync(resultsBase)
              .filter(d => fs.statSync(path.join(resultsBase, d)).isDirectory())
              .sort()
              .reverse();

            if (dirs.length === 0) {
              console.log('No benchmark results found');
              return;
            }

            const latestDir = path.join(resultsBase, dirs[0]);
            const summaryFile = path.join(latestDir, 'summary.txt');

            if (!fs.existsSync(summaryFile)) {
              console.log('Summary file not found');
              return;
            }

            // Parse PR results
            const prSummary = fs.readFileSync(summaryFile, 'utf8');
            const { results: prResults, bottleneck: prBottleneck } = parseSummary(prSummary);

            // Parse baseline results (if available)
            let baselineResults = null;
            let baselineBottleneck = null;
            const baselineFile = '/tmp/baseline_summary.txt';
            if (fs.existsSync(baselineFile)) {
              const baselineSummary = fs.readFileSync(baselineFile, 'utf8');
              const parsed = parseSummary(baselineSummary);
              baselineResults = parsed.results;
              baselineBottleneck = parsed.bottleneck;
            }

            if (prResults.size === 0) {
              console.log('No benchmark results parsed');
              return;
            }

            // Build comparison table with P99 latency
            let table = '| Endpoint | Req/s (PR) | Req/s (main) | Change | P99 (PR) |\n';
            table += '|----------|----------:|------------:|-------:|--------:|\n';

            let totalPr = 0;
            let totalMain = 0;
            let count = 0;

            for (const [name, pr] of prResults) {
              const prReqs = pr.reqsPerSec;
              totalPr += prReqs;
              count++;

              let mainReqs = '-';
              let change = '-';
              const p99 = pr.p99 || '-';

              if (baselineResults && baselineResults.has(name)) {
                const baseline = baselineResults.get(name);
                mainReqs = baseline.reqsPerSec.toLocaleString('en-US', {maximumFractionDigits: 2});
                totalMain += baseline.reqsPerSec;

                const diff = ((prReqs - baseline.reqsPerSec) / baseline.reqsPerSec) * 100;
                if (diff > 0) {
                  change = `+${diff.toFixed(2)}% :arrow_up:`;
                } else if (diff < 0) {
                  change = `${diff.toFixed(2)}% :arrow_down:`;
                } else {
                  change = '0%';
                }
              }

              table += `| ${name} | ${prReqs.toLocaleString('en-US', {maximumFractionDigits: 2})} | ${mainReqs} | ${change} | ${p99} |\n`;
            }

            // Add average row
            const avgPr = totalPr / count;
            let avgMain = '-';
            let avgChange = '-';

            if (baselineResults && totalMain > 0) {
              avgMain = (totalMain / count).toLocaleString('en-US', {maximumFractionDigits: 2});
              const avgMainNum = totalMain / count;
              const diff = ((avgPr - avgMainNum) / avgMainNum) * 100;
              if (diff > 0) {
                avgChange = `+${diff.toFixed(2)}% :arrow_up:`;
              } else if (diff < 0) {
                avgChange = `${diff.toFixed(2)}% :arrow_down:`;
              } else {
                avgChange = '0%';
              }
            }

            table += `| **Average** | **${avgPr.toLocaleString('en-US', {maximumFractionDigits: 2})}** | **${avgMain}** | **${avgChange}** | - |\n`;

            // Build bottleneck analysis section
            let bottleneckSection = '';
            if (prBottleneck.slowest || prBottleneck.highestP99) {
              bottleneckSection = '\n### :mag: Bottleneck Analysis\n\n';
              if (prBottleneck.slowest) {
                bottleneckSection += `- **Slowest endpoint**: \`${prBottleneck.slowest.name}\` (${prBottleneck.slowest.rps.toLocaleString('en-US', {maximumFractionDigits: 2})} req/s)\n`;
              }
              if (prBottleneck.highestP99) {
                bottleneckSection += `- **Highest P99 latency**: \`${prBottleneck.highestP99.name}\` (${prBottleneck.highestP99.latency})\n`;
              }
            }

            // Determine overall status
            let status = ':white_check_mark: Benchmark completed';
            if (baselineResults) {
              const avgMainNum = totalMain / count;
              const overallDiff = ((avgPr - avgMainNum) / avgMainNum) * 100;
              if (overallDiff < -5) {
                status = ':warning: Performance regression detected (>' + Math.abs(overallDiff).toFixed(1) + '% slower)';
              } else if (overallDiff > 5) {
                status = ':rocket: Performance improvement detected (+' + overallDiff.toFixed(1) + '% faster)';
              } else {
                status = ':white_check_mark: No significant performance change';
              }
            }

            const body = [
              '## :rocket: API Workload Benchmark Results',
              '',
              status,
              '',
              table,
              bottleneckSection,
              '<details>',
              '<summary>Configuration</summary>',
              '',
              '- **Duration**: 10s',
              '- **Threads**: 2',
              '- **Connections**: 10',
              '- **Mode**: Quick test',
              '',
              '</details>',
              '',
              `> Benchmark run at: ${new Date().toISOString()}`
            ].join('\n');

            // Find existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('## :rocket: API Workload Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results-${{ github.sha }}
          path: benches/api/benchmarks/results/
          retention-days: 30

      - name: Cleanup
        if: always()
        working-directory: benches/api/docker
        run: docker compose -f compose.ci.yaml down -v
