name: API Workload Benchmark

on:
  push:
    branches: [main]
    paths:
      - 'benches/api/**'
      - 'src/**'
      - 'lambars-derive/**'
      - 'Cargo.toml'
      - 'Cargo.lock'
  pull_request:
    paths:
      - 'benches/api/**'
      - 'src/**'
      - 'lambars-derive/**'
      - 'Cargo.toml'
      - 'Cargo.lock'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  benchmark:
    name: API Workload Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and start services
        working-directory: benches/api/docker
        run: |
          docker compose -f compose.ci.yaml up -d --build --wait
          docker compose -f compose.ci.yaml ps

      - name: Install wrk
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk

      - name: Setup test data
        working-directory: benches/api/benchmarks
        run: |
          chmod +x setup_test_data.sh
          API_URL=http://localhost:3002 ./setup_test_data.sh

      - name: Run benchmarks
        id: benchmark
        working-directory: benches/api/benchmarks
        continue-on-error: true
        run: |
          chmod +x run_benchmark.sh
          API_URL=http://localhost:3002 DURATION=10s THREADS=2 CONNECTIONS=10 ./run_benchmark.sh --quick

      - name: Show API logs on failure
        if: failure()
        working-directory: benches/api/docker
        run: |
          echo "=== API Container Logs ==="
          docker compose -f compose.ci.yaml logs api --tail=100
          echo ""
          echo "=== Container Status ==="
          docker compose -f compose.ci.yaml ps -a

      - name: Check benchmark results
        working-directory: benches/api/benchmarks
        run: |
          # Find the most recent results directory
          RESULTS_DIR=$(ls -td results/*/ 2>/dev/null | head -1)
          if [ -z "$RESULTS_DIR" ]; then
            echo "No benchmark results found!"
            exit 1
          fi

          echo "Checking results in: $RESULTS_DIR"
          echo ""

          # Count successful benchmarks (those with actual requests)
          TOTAL=0
          PASSED=0
          FAILED_BENCHMARKS=""

          for result_file in "$RESULTS_DIR"/*.txt; do
            if [ -f "$result_file" ] && [ "$(basename "$result_file")" != "summary.txt" ]; then
              TOTAL=$((TOTAL + 1))
              BENCHMARK_NAME=$(basename "$result_file" .txt)

              # Check if requests were made (not 0 requests)
              REQUESTS=$(grep -o '[0-9]* requests in' "$result_file" | head -1 | awk '{print $1}')
              if [ -n "$REQUESTS" ] && [ "$REQUESTS" -gt 0 ]; then
                PASSED=$((PASSED + 1))
                echo "  $BENCHMARK_NAME: PASSED ($REQUESTS requests)"
              else
                FAILED_BENCHMARKS="$FAILED_BENCHMARKS $BENCHMARK_NAME"
                echo "  $BENCHMARK_NAME: FAILED (0 requests)"
              fi
            fi
          done

          echo ""
          echo "Summary: $PASSED/$TOTAL benchmarks passed"

          if [ "$PASSED" -lt "$TOTAL" ]; then
            echo ""
            echo "Failed benchmarks:$FAILED_BENCHMARKS"
            echo ""
            echo "This may indicate API issues. Check the API logs above."
            exit 1
          fi

      - name: Post benchmark results as PR comment
        if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Find the most recent results directory
            const resultsBase = 'benches/api/benchmarks/results';
            const dirs = fs.readdirSync(resultsBase)
              .filter(d => fs.statSync(path.join(resultsBase, d)).isDirectory())
              .sort()
              .reverse();

            if (dirs.length === 0) {
              console.log('No benchmark results found');
              return;
            }

            const latestDir = path.join(resultsBase, dirs[0]);
            const summaryFile = path.join(latestDir, 'summary.txt');

            if (!fs.existsSync(summaryFile)) {
              console.log('Summary file not found');
              return;
            }

            // Parse summary file to extract metrics
            const summary = fs.readFileSync(summaryFile, 'utf8');
            const lines = summary.split('\n');

            // Build results table
            const results = [];
            let currentBenchmark = null;
            let reqsPerSec = null;
            let avgLatency = null;

            for (const line of lines) {
              const benchMatch = line.match(/^(\w+):$/);
              if (benchMatch) {
                if (currentBenchmark && reqsPerSec) {
                  results.push({ name: currentBenchmark, reqsPerSec, avgLatency });
                }
                currentBenchmark = benchMatch[1];
                reqsPerSec = null;
                avgLatency = null;
              }
              const reqsMatch = line.match(/Requests\/sec:\s*([\d.]+)/);
              if (reqsMatch) {
                reqsPerSec = parseFloat(reqsMatch[1]);
              }
              const latencyMatch = line.match(/Avg Latency:\s*([\d.]+\w+)/);
              if (latencyMatch) {
                avgLatency = latencyMatch[1];
              }
            }
            // Don't forget the last one
            if (currentBenchmark && reqsPerSec) {
              results.push({ name: currentBenchmark, reqsPerSec, avgLatency });
            }

            if (results.length === 0) {
              console.log('No benchmark results parsed');
              return;
            }

            // Calculate total and average
            const totalReqs = results.reduce((sum, r) => sum + r.reqsPerSec, 0);
            const avgReqs = totalReqs / results.length;

            // Build markdown table
            let table = '| Endpoint | Requests/sec | Avg Latency |\n';
            table += '|----------|-------------:|------------:|\n';
            for (const r of results) {
              table += `| ${r.name} | ${r.reqsPerSec.toLocaleString('en-US', {maximumFractionDigits: 2})} | ${r.avgLatency || 'N/A'} |\n`;
            }
            table += `| **Average** | **${avgReqs.toLocaleString('en-US', {maximumFractionDigits: 2})}** | - |\n`;

            const body = [
              '## ðŸš€ API Workload Benchmark Results',
              '',
              table,
              '<details>',
              '<summary>Configuration</summary>',
              '',
              '- **Duration**: 10s',
              '- **Threads**: 2',
              '- **Connections**: 10',
              '- **Mode**: Quick test',
              '',
              '</details>',
              '',
              `> Benchmark run at: ${new Date().toISOString()}`
            ].join('\n');

            // Find existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('## ðŸš€ API Workload Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results-${{ github.sha }}
          path: benches/api/benchmarks/results/
          retention-days: 30

      - name: Cleanup
        if: always()
        working-directory: benches/api/docker
        run: docker compose -f compose.ci.yaml down -v
